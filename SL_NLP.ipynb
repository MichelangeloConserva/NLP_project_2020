{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SL_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwJichzB1SII",
        "colab_type": "code",
        "outputId": "e82c34c9-4934-4418-ca84-e080cee5d549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# SET THIS TRUE AND RUN WHEN UPDATE NEEDED\n",
        "update = True\n",
        "\n",
        "if update:\n",
        "  # Installing and updating the repository\n",
        "  ! pip install --upgrade git+https://MichelangeloConserva:NLP_project_2020@github.com/MichelangeloConserva/NLP_project_2020.git\n",
        "# Restarting the kernel to make the changes effective\n",
        "if update: import os; os.kill(os.getpid(), 9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://MichelangeloConserva:****@github.com/MichelangeloConserva/NLP_project_2020.git\n",
            "  Cloning https://MichelangeloConserva:****@github.com/MichelangeloConserva/NLP_project_2020.git to /tmp/pip-req-build-4uxk5imc\n",
            "  Running command git clone -q 'https://MichelangeloConserva:****@github.com/MichelangeloConserva/NLP_project_2020.git' /tmp/pip-req-build-4uxk5imc\n",
            "Requirement already satisfied, skipping upgrade: gym in /usr/local/lib/python3.6/dist-packages (from nlp2020==0.0.1) (0.15.6)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nlp2020==0.0.1) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym->nlp2020==0.0.1) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->nlp2020==0.0.1) (1.4.10)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from gym->nlp2020==0.0.1) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from gym->nlp2020==0.0.1) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->nlp2020==0.0.1) (1.2.2)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->nlp2020==0.0.1) (0.16.0)\n",
            "Building wheels for collected packages: nlp2020\n",
            "  Building wheel for nlp2020 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nlp2020: filename=nlp2020-0.0.1-cp36-none-any.whl size=23232 sha256=c93e1b6090f34c07ed68f2e95295c4a21154681bd119038f73eeb56a0f3018e2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g68j1r_a/wheels/e9/2f/fe/49c0ce8f81713ff795534e9cd3291fe52acc8553e34207175d\n",
            "Successfully built nlp2020\n",
            "Installing collected packages: nlp2020\n",
            "Successfully installed nlp2020-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHHY6UWAl-Pn",
        "colab_type": "code",
        "outputId": "16c04fb7-2013-412c-88e8-e5978e256224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/58/3d789b98923da6485f376be1e04d59ad7003a63bdb2b04b5eea7e02857e5/transformers-2.5.0-py3-none-any.whl (481kB)\n",
            "\r\u001b[K     |▊                               | 10kB 22.7MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 399kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 409kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 419kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 430kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 440kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 450kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 460kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 471kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 491kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/1d/ea7e2c628942e686595736f73678348272120d026b7acd54fe43e5211bb1/tokenizers-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 62.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 56.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=3b4fbbfe0ceed04fce806546549a78146fa9dbe16d0e40121eb77138aef3221f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.0 transformers-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y2Lspgrnb2H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "744a9fbf-3a07-480e-d3a0-a114c3eed253"
      },
      "source": [
        "# Imports\n",
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(precision=3, suppress=1)\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from itertools import count\n",
        "\n",
        "from nlp2020.agents.random_agent import RandomAgent\n",
        "from nlp2020.agents.dqn_agent import DQN_agent\n",
        "from nlp2020.agents.acer_agent import ACER_agent\n",
        "from nlp2020.utils import smooth\n",
        "from nlp2020.train_test_functions import train1, test1\n",
        "from nlp2020.dung_descr_score import dungeon_description_generator\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "import torch\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LusXzOzSjKc6",
        "colab_type": "text"
      },
      "source": [
        "# Creating the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6hkycddDxeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = []\n",
        "train_y_temp = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZxSPzoBBU-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5000):\n",
        "  description, label, _ = dungeon_description_generator()\n",
        "  train_x.append(description)\n",
        "  train_y_temp.append(label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFfq1CS5Un_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def int_to_onehot(n, n_classes):\n",
        "    v = [0] * n_classes\n",
        "    v[n] = 1\n",
        "    return v\n",
        "\n",
        "def onehot_to_int(v):\n",
        "    return v.index(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqyjoB5hUn6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = []\n",
        "for i in train_y_temp:\n",
        "  train_y.append(onehot_to_int(i.tolist()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJMc58I5b9jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ0Rt-5rcI5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me2HGIaOjObS",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bteaIXjPh1t_",
        "colab_type": "code",
        "outputId": "d4cf725f-0f49-44d5-b9c1-10f5709506ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in train_x:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train_x[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:   A small wooden sign lies in front of the entrance of the dungeon. You \n",
            "    begin to read it...\n",
            "    You are about to enter a small dungeon with spiderwebs as far as the eye can see. \n",
            "    Your path will be full of perils: horrifying monsters live in the dungeon behind this intimidating door. \n",
            "    Their nutrition consists mostly of nuts and humans.\n",
            "    Further, nature will not always be on your side: blazing winds will slow down your quest; \n",
            "    unstable weather will modify the effectiveness of your weapons. \n",
            "    Dangerously peaked plants will have to be avoided.\n",
            "    Twisted trails with the constant threat of slippery stones will have you always one step \n",
            "    closer to death. \n",
            "    No need to be disheartened though! You can bring weapons with you young hero. Choose among \n",
            "    the weapons next to this sign. You must make this choice wisely. It’s a matter of \n",
            "    life and death! \n",
            "    Go on to your adventure now and remember to bring a book. \n",
            "\n",
            "Token IDs: [101, 1037, 2235, 4799, 3696, 3658, 1999, 2392, 1997, 1996, 4211, 1997, 1996, 16633, 1012, 2017, 4088, 2000, 3191, 2009, 1012, 1012, 1012, 2017, 2024, 2055, 2000, 4607, 1037, 2235, 16633, 2007, 6804, 8545, 5910, 2004, 2521, 2004, 1996, 3239, 2064, 2156, 1012, 2115, 4130, 2097, 2022, 2440, 1997, 2566, 12146, 1024, 7570, 18752, 14116, 9219, 2444, 1999, 1996, 16633, 2369, 2023, 24439, 2341, 1012, 2037, 14266, 3774, 3262, 1997, 12264, 1998, 4286, 1012, 2582, 1010, 3267, 2097, 2025, 2467, 2022, 2006, 2115, 2217, 1024, 17162, 7266, 2097, 4030, 2091, 2115, 8795, 1025, 14480, 4633, 2097, 19933, 1996, 12353, 1997, 2115, 4255, 1012, 20754, 6601, 4264, 2097, 2031, 2000, 2022, 9511, 1012, 6389, 9612, 2007, 1996, 5377, 5081, 1997, 22274, 6386, 2097, 2031, 2017, 2467, 2028, 3357, 3553, 2000, 2331, 1012, 2053, 2342, 2000, 2022, 9841, 14644, 6528, 2098, 2295, 999, 2017, 2064, 3288, 4255, 2007, 2017, 2402, 5394, 1012, 5454, 2426, 1996, 4255, 2279, 2000, 2023, 3696, 1012, 2017, 2442, 2191, 2023, 3601, 7968, 2135, 1012, 2009, 1521, 1055, 1037, 3043, 1997, 2166, 1998, 2331, 999, 2175, 2006, 2000, 2115, 6172, 2085, 1998, 3342, 2000, 3288, 1037, 2338, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBCqkc1akbCi",
        "colab_type": "code",
        "outputId": "1892a2ea-816f-40fc-9ee0-6bbe664322ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdxrElCXjkYi",
        "colab_type": "text"
      },
      "source": [
        "# Add padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ang-IMIBkfwg",
        "colab_type": "code",
        "outputId": "6c34e0d2-6ed8-49ee-beb4-2d53e9eba294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 201\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 201 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY350CH8kj22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xtC3LThkpjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, train_y, \n",
        "                                                            random_state=2018, test_size=0.5)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, train_y,\n",
        "                                             random_state=2018, test_size=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVi7KxfylBP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XbuD_EIinqR",
        "colab_type": "code",
        "outputId": "27e8badf-295f-490a-b581-7aef11de77e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"number of train set: \", len(train_labels))\n",
        "print(\"number of validation set: \", len(validation_labels))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of train set:  2500\n",
            "number of validation set:  2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZCIOtQBlPjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BriNvCZikG9Z",
        "colab_type": "text"
      },
      "source": [
        "# Download BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV_Romb1lSN_",
        "colab_type": "code",
        "outputId": "69abdb42-ba8e-4337-f956-3359839a5165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 5, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyGpSSOENyqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPEnhVIFmN6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQOk7LMEmQTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbKxEzX2mSp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3FP_rzDkl7L",
        "colab_type": "text"
      },
      "source": [
        "# Train the model with 2500 training, 2500 validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25SCmDkcmUv1",
        "colab_type": "code",
        "outputId": "2ab6b32e-a85c-4ff2-822c-9782daa92278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     79.    Elapsed: 0:00:24.\n",
            "\n",
            "  Average training loss: 1.21\n",
            "  Training epcoh took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     79.    Elapsed: 0:00:24.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     79.    Elapsed: 0:00:24.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epcoh took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     79.    Elapsed: 0:00:24.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation took: 0:00:15\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpvSCR8hzcew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "0d24f6c6-3941-49b4-d629-79815635d54c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6k7YIW8J3/QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7XoRgP7nZeZ",
        "colab_type": "text"
      },
      "source": [
        "#Test phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWmPcXvyl1Ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the dataset.\n",
        "test_x = []\n",
        "test_y_temp = []\n",
        "\n",
        "for i in range(10000):\n",
        "  description, label, _ = dungeon_description_generator()\n",
        "  test_x.append(description)\n",
        "  test_y_temp.append(label)\n",
        "\n",
        "test_y = []\n",
        "for i in test_y_temp:\n",
        "  test_y.append(onehot_to_int(i.tolist()))\n",
        "\n",
        "\n",
        "sentences = test_x\n",
        "labels = test_y\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byqX7tTrnXnE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "64506588-470e-420e-ae6a-ff53c6b6a605"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 10,000 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux-JkP26p_ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = torch.tensor(predictions[0])\n",
        "true_label = torch.tensor(true_labels[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRy3yA-XqS4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "544fd72c-19c9-49e7-8208-e5ec9494221a"
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "for i in range(len(predictions)):\n",
        "  prediction = torch.tensor(predictions[i])\n",
        "  true_label = torch.tensor(true_labels[i])\n",
        "  _, pred = torch.max(prediction, 1) \n",
        "  total += len(_)\n",
        "  correct += (pred==true_label).sum().item()\n",
        "print(\"Test Accuracy: \", 100 * correct / total)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  99.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnCOtI4Woj3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}