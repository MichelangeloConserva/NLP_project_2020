{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mqp0Q15zZrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "77053500-4726-47f0-b9ce-613892df657a"
      },
      "source": [
        "# SET THIS TRUE AND RUN WHEN UPDATE NEEDED\n",
        "update = True\n",
        "\n",
        "if update:\n",
        "  # Installing and updating the repository\n",
        "  ! pip install --upgrade git+https://MichelangeloConserva:NLP_project_2020@github.com/MichelangeloConserva/NLP_project_2020.git\n",
        "# Restarting the kernel to make the changes effective\n",
        "if update: import os; os.kill(os.getpid(), 9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://MichelangeloConserva:****@github.com/MichelangeloConserva/NLP_project_2020.git\n",
            "  Cloning https://MichelangeloConserva:****@github.com/MichelangeloConserva/NLP_project_2020.git to /tmp/pip-req-build-ky7jy2a9\n",
            "  Running command git clone -q 'https://MichelangeloConserva:****@github.com/MichelangeloConserva/NLP_project_2020.git' /tmp/pip-req-build-ky7jy2a9\n",
            "Requirement already satisfied, skipping upgrade: gym in /usr/local/lib/python3.6/dist-packages (from nlp2020==0.0.1) (0.15.6)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nlp2020==0.0.1) (4.28.1)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from gym->nlp2020==0.0.1) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->nlp2020==0.0.1) (1.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->nlp2020==0.0.1) (1.4.10)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym->nlp2020==0.0.1) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from gym->nlp2020==0.0.1) (1.4.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 62.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->nlp2020==0.0.1) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers->nlp2020==0.0.1) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers->nlp2020==0.0.1) (1.11.15)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->nlp2020==0.0.1) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 47.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->nlp2020==0.0.1) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->nlp2020==0.0.1) (7.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->nlp2020==0.0.1) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->nlp2020==0.0.1) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->nlp2020==0.0.1) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->nlp2020==0.0.1) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->nlp2020==0.0.1) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers->nlp2020==0.0.1) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers->nlp2020==0.0.1) (0.9.4)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers->nlp2020==0.0.1) (1.14.15)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers->nlp2020==0.0.1) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers->nlp2020==0.0.1) (0.15.2)\n",
            "Building wheels for collected packages: nlp2020, sacremoses\n",
            "  Building wheel for nlp2020 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nlp2020: filename=nlp2020-0.0.1-cp36-none-any.whl size=31570 sha256=438d0118f63ff0691e6dae5fcd02cb7046d04bdbcfdd782528355c01f9d44c9f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vzs_1lot/wheels/e9/2f/fe/49c0ce8f81713ff795534e9cd3291fe52acc8553e34207175d\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=e8b740400b94373d9159c5719b8854427af59a25b089e6fb8a8830c4002bf255\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built nlp2020 sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers, nlp2020\n",
            "Successfully installed nlp2020-0.0.1 sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1eisWdlzbDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(precision=3, suppress=1)\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from itertools import count\n",
        "\n",
        "from nlp2020.agents.random_agent import RandomAgent\n",
        "from nlp2020.agents.dqn_agent import DQN_agent\n",
        "from nlp2020.agents.acer_agent import ACER_agent\n",
        "from nlp2020.utils import smooth\n",
        "from nlp2020.train_test_functions import train1, test1\n",
        "from nlp2020.dung_descr_score import dungeon_description_generator\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "import torch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGLXS3790110",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsHDgxkhziwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def int_to_onehot(n, n_classes):\n",
        "    v = [0] * n_classes\n",
        "    v[n] = 1\n",
        "    return v\n",
        "\n",
        "def onehot_to_int(v):\n",
        "    return v.index(1)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "\n",
        "train_x = []\n",
        "train_y_temp = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(2000):\n",
        "  description, label, _ = dungeon_description_generator()\n",
        "  train_x.append(description)\n",
        "  train_y_temp.append(label)\n",
        "\n",
        "for i in train_y_temp:\n",
        "  train_y.append(onehot_to_int(i.tolist()))\n",
        "\n",
        "\n",
        "\n",
        "val_x = []\n",
        "val_y_temp = []\n",
        "val_y = []\n",
        "\n",
        "for i in range(2000):\n",
        "  description, label, _ = dungeon_description_generator()\n",
        "  val_x.append(description)\n",
        "  val_y_temp.append(label)\n",
        "\n",
        "for i in val_y_temp:\n",
        "  val_y.append(onehot_to_int(i.tolist()))\n",
        "\n",
        "\n",
        "test_x = []\n",
        "test_y_temp = []\n",
        "test_y = []\n",
        "\n",
        "for i in range(2000):\n",
        "  description, label, _ = dungeon_description_generator()\n",
        "  test_x.append(description)\n",
        "  test_y_temp.append(label)\n",
        "\n",
        "for i in test_y_temp:\n",
        "  test_y.append(onehot_to_int(i.tolist()))\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho1Q5erk1TT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(tokenize = 'spacy')\n",
        "LABEL = data.LabelField()\n",
        "SEED = 1234\n",
        "MAX_VOCAB_SIZE = 25_000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjw3oqS8zoKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(TrainData, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZk2KuImTuf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datafields = [('text', TEXT), ('label', LABEL)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N8FUSWeAxqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL.build_vocab(train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25BP4mhrA0ST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d62de3e8-5391-456e-bfe9-dde3eb1f9804"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f072e1669d8>, {2: 0, 3: 1, 4: 2, 0: 3, 1: 4})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNDU-XlTEAgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ListToTorchtext():\n",
        "  train = []\n",
        "  for i,line in enumerate(train_x):\n",
        "    doc = line.split()\n",
        "    train.append(torchtext.data.Example.fromlist([doc, train_y[i]], datafields))\n",
        "  val = []\n",
        "  for i,line in enumerate(val_x):\n",
        "    doc = line.split()\n",
        "    val.append(torchtext.data.Example.fromlist([doc, val_y[i]], datafields))\n",
        "  test = []\n",
        "  for i,line in enumerate(test_x):\n",
        "    doc = line.split()\n",
        "    test.append(torchtext.data.Example.fromlist([doc, test_y[i]], datafields))\n",
        "  return torchtext.data.Dataset(train, datafields), torchtext.data.Dataset(val, datafields), torchtext.data.Dataset(test, datafields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rbcintHEMd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainData, ValData, TestData = ListToTorchtext()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT2onlTvORFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "309d65e4-bd39-4110-b16f-68dd57325f73"
      },
      "source": [
        ""
      ],
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.data.dataset.Dataset at 0x7f065276f5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLAOgGtZNL9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (TrainData, ValData, TestData), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8vnpcB4bIM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_iterator = torchtext.data.Iterator(\n",
        "    ValData,\n",
        "    device=device,\n",
        "    batch_size=128,\n",
        "    repeat=False,\n",
        "    train=False,\n",
        "    sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8GRg6bpK_DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        text = text.permute(1, 0)\n",
        "                \n",
        "        #text = [batch size, sent len]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #embedded = [batch size, 1, sent len, emb dim]\n",
        "        \n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "            \n",
        "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
        "        \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        \n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zEP8tSALFhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [2,3,4]\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcqf1cpxUeCh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f5f796b-3b54-455a-cfb3-47542c112287"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 92,005 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYDdzcg3Ue-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "82c5f1d7-9ca0-43d0-9a52-fc31102687d0"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3489,  1.8470,  1.9254, -0.5904, -2.3886, -1.5807,  0.1606,  0.0781,\n",
              "         -0.5321,  1.1993, -0.5231,  0.7373, -1.4904, -0.6534,  1.8010, -0.9689,\n",
              "         -0.6290,  0.5096, -0.8333,  0.2098, -0.6421, -0.3646, -0.5480,  1.9573,\n",
              "          1.0590,  0.7137, -1.3119, -0.7797, -1.1794,  0.6845,  1.1306, -0.6998,\n",
              "          1.7359, -1.8885, -1.0175,  1.3947,  0.1751,  0.3768,  0.5822, -0.5450,\n",
              "         -1.0088, -1.0422, -0.1719,  0.7662, -1.5182, -0.6409,  0.2043,  0.0586,\n",
              "          1.4441, -1.2492,  1.2870,  0.6157,  0.5421, -1.3038,  1.0494,  1.3932,\n",
              "          0.1698, -0.7759, -0.7399, -1.1868,  0.5589, -0.0112,  1.1073, -0.8145,\n",
              "          0.2433, -0.6203, -0.8813, -0.5240, -1.6888, -2.3371, -0.6737, -0.7195,\n",
              "         -0.7163, -0.1215,  0.5552, -1.0238, -0.9167,  0.9794, -0.3930,  0.7417,\n",
              "         -0.9288,  0.2216, -0.7602,  0.6865,  0.8952,  0.2089, -0.4964,  1.3622,\n",
              "         -1.4438,  0.3354,  0.4668, -0.6442,  1.3991, -0.6891, -1.4951, -0.5666,\n",
              "         -0.6962,  0.5829,  0.3063, -0.4193],\n",
              "        [-1.5201,  0.8240,  0.7421, -1.0605, -0.5770, -0.7091,  0.7868, -0.1055,\n",
              "         -0.4945, -0.3892,  0.3470, -1.3319, -1.3885, -2.1121,  0.5910,  0.8996,\n",
              "          0.2276,  0.0906,  0.6187, -2.0888, -1.3055,  0.3177,  1.7777,  0.7121,\n",
              "          0.4962,  0.5571,  0.6908,  1.4985, -0.9600, -1.2018, -1.1096, -1.6431,\n",
              "         -0.8006, -0.8747, -1.2965, -0.1821, -0.4256,  0.3473,  1.2045,  0.1199,\n",
              "          1.0147,  0.1768, -2.2119,  1.4340,  0.5543, -0.0851, -0.0132, -2.1534,\n",
              "          0.1686,  0.9935,  1.2136, -0.0174,  0.3305,  1.0132,  0.0782,  0.5144,\n",
              "          1.1647,  0.8039, -1.0559,  1.2640, -0.4535,  1.0252,  1.6338, -1.1076,\n",
              "          0.1396, -0.0224,  1.1541,  0.1254,  1.0868, -0.5985, -0.0106,  0.6723,\n",
              "         -0.0494, -1.3923, -0.8677, -0.2125,  1.4447, -0.7862,  0.4609,  0.9958,\n",
              "         -0.1968, -0.7739,  0.2907,  0.1683,  0.4503,  0.1343, -0.4809, -1.0553,\n",
              "         -1.0166,  1.4600,  0.4104,  1.2410, -1.6129, -0.2969,  0.6025, -0.8627,\n",
              "          0.4266, -0.3308,  0.0082, -0.8149]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKa6Rp37UgcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3KC4cboUhoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO4XaFC9UimA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZBLyUySYcSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "58c6a20e-5883-4fc8-d31e-91c9e6691c92"
      },
      "source": [
        "valid_iterator.__dict__"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_iterations_this_epoch': 16,\n",
              " '_random_state_this_epoch': (3,\n",
              "  (2147483648,\n",
              "   3151590589,\n",
              "   239507051,\n",
              "   537285379,\n",
              "   2111980357,\n",
              "   3280901841,\n",
              "   115536178,\n",
              "   3598296692,\n",
              "   1800536855,\n",
              "   2511930953,\n",
              "   295066150,\n",
              "   3303980234,\n",
              "   567234961,\n",
              "   3820362305,\n",
              "   1666964233,\n",
              "   3371985534,\n",
              "   3665899581,\n",
              "   3440126351,\n",
              "   2876416348,\n",
              "   2237136561,\n",
              "   3091056401,\n",
              "   1947393822,\n",
              "   1200096145,\n",
              "   2564597530,\n",
              "   913087348,\n",
              "   1861862725,\n",
              "   2389782990,\n",
              "   2924915549,\n",
              "   4061695726,\n",
              "   326722144,\n",
              "   370852517,\n",
              "   2493138427,\n",
              "   2586771496,\n",
              "   3614354956,\n",
              "   1487382507,\n",
              "   2701810535,\n",
              "   1428282389,\n",
              "   177086867,\n",
              "   2877803366,\n",
              "   2272028482,\n",
              "   1908026348,\n",
              "   2365408123,\n",
              "   3512232534,\n",
              "   162591178,\n",
              "   596480697,\n",
              "   3841149392,\n",
              "   256443461,\n",
              "   4017953277,\n",
              "   397530297,\n",
              "   1756056303,\n",
              "   3564203977,\n",
              "   290303792,\n",
              "   1710572730,\n",
              "   122334795,\n",
              "   2833888092,\n",
              "   4062051185,\n",
              "   4012425478,\n",
              "   3579617659,\n",
              "   4163888094,\n",
              "   1617305536,\n",
              "   4039434764,\n",
              "   2142462441,\n",
              "   3914620657,\n",
              "   3496238664,\n",
              "   1855951297,\n",
              "   3709167320,\n",
              "   3400635977,\n",
              "   736735024,\n",
              "   392109383,\n",
              "   1903834654,\n",
              "   2700044725,\n",
              "   753420329,\n",
              "   2165781267,\n",
              "   446946141,\n",
              "   1150118661,\n",
              "   2217369894,\n",
              "   776107393,\n",
              "   53412821,\n",
              "   2470796948,\n",
              "   1090127711,\n",
              "   3688650381,\n",
              "   3163264618,\n",
              "   2950916094,\n",
              "   488349747,\n",
              "   1126965770,\n",
              "   3677008302,\n",
              "   2668831917,\n",
              "   939216280,\n",
              "   464443751,\n",
              "   4290128514,\n",
              "   784716609,\n",
              "   286749216,\n",
              "   2540886733,\n",
              "   3315991116,\n",
              "   440423806,\n",
              "   3121716811,\n",
              "   2795027453,\n",
              "   3748673501,\n",
              "   864704063,\n",
              "   347507456,\n",
              "   3433536221,\n",
              "   1424023073,\n",
              "   2783875505,\n",
              "   3862836304,\n",
              "   4064349364,\n",
              "   3152052549,\n",
              "   1961889952,\n",
              "   4097793500,\n",
              "   1801736528,\n",
              "   691448159,\n",
              "   1532926602,\n",
              "   424687937,\n",
              "   2368109361,\n",
              "   1144792926,\n",
              "   1844854787,\n",
              "   837695961,\n",
              "   884082321,\n",
              "   683569474,\n",
              "   3072220374,\n",
              "   3118539026,\n",
              "   2279146967,\n",
              "   2404606043,\n",
              "   3838383955,\n",
              "   2805708026,\n",
              "   1243833274,\n",
              "   731763506,\n",
              "   2573766289,\n",
              "   3716365586,\n",
              "   2798515917,\n",
              "   2514203974,\n",
              "   3442491046,\n",
              "   3192437109,\n",
              "   2261785812,\n",
              "   579661361,\n",
              "   3422117815,\n",
              "   3481475143,\n",
              "   898359026,\n",
              "   1103362813,\n",
              "   3110137626,\n",
              "   2400275445,\n",
              "   2819938480,\n",
              "   3470024589,\n",
              "   1568837551,\n",
              "   3601027949,\n",
              "   3551083701,\n",
              "   1073164937,\n",
              "   3846344526,\n",
              "   395569761,\n",
              "   3870565971,\n",
              "   521398345,\n",
              "   952097517,\n",
              "   3620995482,\n",
              "   3079125183,\n",
              "   1797004182,\n",
              "   3808374203,\n",
              "   4048039447,\n",
              "   3476336733,\n",
              "   1837578047,\n",
              "   3064980217,\n",
              "   3995552607,\n",
              "   882223638,\n",
              "   1347054482,\n",
              "   884999087,\n",
              "   2855811330,\n",
              "   1498758301,\n",
              "   163762269,\n",
              "   3177380513,\n",
              "   463718249,\n",
              "   3636751385,\n",
              "   884343762,\n",
              "   1108442465,\n",
              "   1432904858,\n",
              "   3962840811,\n",
              "   2900218459,\n",
              "   1400177474,\n",
              "   1374315618,\n",
              "   652736143,\n",
              "   722448630,\n",
              "   527621064,\n",
              "   541788346,\n",
              "   345539332,\n",
              "   1625908413,\n",
              "   424122130,\n",
              "   1993311247,\n",
              "   1242261168,\n",
              "   4259935667,\n",
              "   1244280499,\n",
              "   2291722060,\n",
              "   4110132895,\n",
              "   1209140078,\n",
              "   24777007,\n",
              "   2088086323,\n",
              "   3373103225,\n",
              "   3991738724,\n",
              "   3905472820,\n",
              "   3095288045,\n",
              "   755804181,\n",
              "   2258325602,\n",
              "   2697352844,\n",
              "   802315512,\n",
              "   1420768853,\n",
              "   3491581559,\n",
              "   2408996913,\n",
              "   1403943420,\n",
              "   3437432757,\n",
              "   2277102820,\n",
              "   416885145,\n",
              "   3517119344,\n",
              "   904080690,\n",
              "   1238789205,\n",
              "   2786880566,\n",
              "   2034901772,\n",
              "   2669263639,\n",
              "   2783026872,\n",
              "   3733791942,\n",
              "   2879920080,\n",
              "   1613600290,\n",
              "   713188193,\n",
              "   2214328522,\n",
              "   1386218943,\n",
              "   2870194440,\n",
              "   3750437717,\n",
              "   3588937684,\n",
              "   3492073306,\n",
              "   2398838825,\n",
              "   891393563,\n",
              "   3017880088,\n",
              "   4285455304,\n",
              "   632501120,\n",
              "   259759703,\n",
              "   1056250325,\n",
              "   1616826667,\n",
              "   1718522007,\n",
              "   791356766,\n",
              "   2546051449,\n",
              "   1362837765,\n",
              "   3161398553,\n",
              "   4098000771,\n",
              "   3228975217,\n",
              "   3686032357,\n",
              "   524924575,\n",
              "   3903736859,\n",
              "   955964776,\n",
              "   2334742329,\n",
              "   2226199947,\n",
              "   2457429377,\n",
              "   16204463,\n",
              "   3831405237,\n",
              "   1870922148,\n",
              "   128511824,\n",
              "   3409315701,\n",
              "   1470303665,\n",
              "   592872062,\n",
              "   1161162123,\n",
              "   868065851,\n",
              "   3637532222,\n",
              "   3593506414,\n",
              "   1248004442,\n",
              "   1686811744,\n",
              "   1447029422,\n",
              "   3176739930,\n",
              "   3284554670,\n",
              "   1317336546,\n",
              "   3308196933,\n",
              "   783883656,\n",
              "   612716382,\n",
              "   2466995514,\n",
              "   311016638,\n",
              "   2553371919,\n",
              "   1974173163,\n",
              "   973943146,\n",
              "   3459368889,\n",
              "   1258980848,\n",
              "   1877637421,\n",
              "   2452281774,\n",
              "   1219826271,\n",
              "   985946395,\n",
              "   2499774589,\n",
              "   1630943832,\n",
              "   1396896169,\n",
              "   3184116410,\n",
              "   2254440911,\n",
              "   3521034011,\n",
              "   2460325660,\n",
              "   2516438481,\n",
              "   4140788918,\n",
              "   1902797662,\n",
              "   3687004635,\n",
              "   2742212085,\n",
              "   4122567199,\n",
              "   185208165,\n",
              "   3018386890,\n",
              "   1675460088,\n",
              "   543220844,\n",
              "   4003728466,\n",
              "   1636026340,\n",
              "   2278991589,\n",
              "   4201145181,\n",
              "   1030718020,\n",
              "   2562678159,\n",
              "   32608943,\n",
              "   1907585706,\n",
              "   3582103727,\n",
              "   854951797,\n",
              "   2748929084,\n",
              "   51314904,\n",
              "   477836599,\n",
              "   2753190986,\n",
              "   503689168,\n",
              "   3266347587,\n",
              "   2456663723,\n",
              "   2775135206,\n",
              "   203810126,\n",
              "   1343494981,\n",
              "   4245916778,\n",
              "   3076989030,\n",
              "   2732919859,\n",
              "   3494214930,\n",
              "   3019121055,\n",
              "   3768875218,\n",
              "   294809799,\n",
              "   3238762680,\n",
              "   1503797182,\n",
              "   126552086,\n",
              "   1252503409,\n",
              "   1470177541,\n",
              "   2607283582,\n",
              "   599903939,\n",
              "   601670233,\n",
              "   4291466476,\n",
              "   551049339,\n",
              "   621298187,\n",
              "   2050707980,\n",
              "   2524644413,\n",
              "   2664862781,\n",
              "   3767414066,\n",
              "   1591644352,\n",
              "   2954461351,\n",
              "   450271656,\n",
              "   3293700054,\n",
              "   3743300483,\n",
              "   4018133282,\n",
              "   2309939901,\n",
              "   2696107562,\n",
              "   1935031734,\n",
              "   1253044821,\n",
              "   2767047158,\n",
              "   1999990706,\n",
              "   2397592677,\n",
              "   4293505567,\n",
              "   1040726362,\n",
              "   1031078271,\n",
              "   103275543,\n",
              "   959244136,\n",
              "   3004146381,\n",
              "   3153605406,\n",
              "   321982401,\n",
              "   4088712433,\n",
              "   3329560974,\n",
              "   2552515461,\n",
              "   4138011111,\n",
              "   2717251905,\n",
              "   1563343721,\n",
              "   1445702395,\n",
              "   3370725123,\n",
              "   1672526725,\n",
              "   2584378621,\n",
              "   2608270329,\n",
              "   654849600,\n",
              "   2040680789,\n",
              "   570397646,\n",
              "   1762729717,\n",
              "   536845575,\n",
              "   2630539069,\n",
              "   3120250930,\n",
              "   2730601687,\n",
              "   1346545313,\n",
              "   1745719802,\n",
              "   3667345540,\n",
              "   2434127074,\n",
              "   2429003291,\n",
              "   545089209,\n",
              "   3545699610,\n",
              "   770960897,\n",
              "   318822210,\n",
              "   3394024654,\n",
              "   4149915884,\n",
              "   2780008460,\n",
              "   2824458345,\n",
              "   2153186036,\n",
              "   1416349156,\n",
              "   802486390,\n",
              "   2817346453,\n",
              "   3875460468,\n",
              "   2979778663,\n",
              "   247473358,\n",
              "   1178694693,\n",
              "   2796263114,\n",
              "   2682050905,\n",
              "   2743593807,\n",
              "   1495418393,\n",
              "   2738631341,\n",
              "   2195929486,\n",
              "   3047955245,\n",
              "   776816820,\n",
              "   418697522,\n",
              "   3655527657,\n",
              "   3312007653,\n",
              "   755624561,\n",
              "   1715956498,\n",
              "   3945601093,\n",
              "   1592855516,\n",
              "   3577381712,\n",
              "   4257004732,\n",
              "   163637263,\n",
              "   2600326636,\n",
              "   3588104113,\n",
              "   1373788965,\n",
              "   2949479873,\n",
              "   89435912,\n",
              "   1639607073,\n",
              "   967097920,\n",
              "   1144748677,\n",
              "   3036523915,\n",
              "   1563312480,\n",
              "   149221848,\n",
              "   3127620581,\n",
              "   2950535428,\n",
              "   144231835,\n",
              "   1297107350,\n",
              "   2918415556,\n",
              "   2247253977,\n",
              "   2241973263,\n",
              "   2259771016,\n",
              "   3243084525,\n",
              "   202859082,\n",
              "   485555810,\n",
              "   1031589914,\n",
              "   133439936,\n",
              "   2550866782,\n",
              "   2768360739,\n",
              "   3391182,\n",
              "   1970399877,\n",
              "   4189157968,\n",
              "   2279866378,\n",
              "   1446945617,\n",
              "   3509883246,\n",
              "   408132503,\n",
              "   2768074287,\n",
              "   1571494281,\n",
              "   3354123752,\n",
              "   1635512890,\n",
              "   4034201117,\n",
              "   2897968089,\n",
              "   337332642,\n",
              "   127471768,\n",
              "   940844505,\n",
              "   3505916797,\n",
              "   1387386192,\n",
              "   424873472,\n",
              "   1910590280,\n",
              "   330940457,\n",
              "   446840747,\n",
              "   1443623501,\n",
              "   2950245645,\n",
              "   621108770,\n",
              "   3292207714,\n",
              "   1229475089,\n",
              "   2085745559,\n",
              "   3129825470,\n",
              "   143144005,\n",
              "   54703874,\n",
              "   3555108940,\n",
              "   2946778484,\n",
              "   4052630687,\n",
              "   2245139664,\n",
              "   1636965000,\n",
              "   3317412589,\n",
              "   3585738147,\n",
              "   2354198767,\n",
              "   4002158386,\n",
              "   77616346,\n",
              "   3132126820,\n",
              "   2875860178,\n",
              "   1806924853,\n",
              "   1716263633,\n",
              "   2125084182,\n",
              "   2969005045,\n",
              "   690980808,\n",
              "   912396207,\n",
              "   441236460,\n",
              "   1386572407,\n",
              "   3248938588,\n",
              "   3710649953,\n",
              "   3388927878,\n",
              "   569601594,\n",
              "   1621172393,\n",
              "   3116855821,\n",
              "   3893404799,\n",
              "   2966042533,\n",
              "   59565243,\n",
              "   2996339828,\n",
              "   1682296737,\n",
              "   588272928,\n",
              "   1946774861,\n",
              "   4176320077,\n",
              "   1499988859,\n",
              "   582475114,\n",
              "   2681142310,\n",
              "   1339769479,\n",
              "   268294994,\n",
              "   1650712217,\n",
              "   4079201367,\n",
              "   2878067310,\n",
              "   2276574009,\n",
              "   505496828,\n",
              "   67651819,\n",
              "   668055090,\n",
              "   4233609014,\n",
              "   1181988179,\n",
              "   1713439927,\n",
              "   160086677,\n",
              "   3917435903,\n",
              "   1247425579,\n",
              "   1126344568,\n",
              "   2591819928,\n",
              "   1691826169,\n",
              "   126431643,\n",
              "   2546586403,\n",
              "   922291503,\n",
              "   2723338806,\n",
              "   2673671646,\n",
              "   923363513,\n",
              "   768316700,\n",
              "   1779120886,\n",
              "   776434771,\n",
              "   2653335078,\n",
              "   220376727,\n",
              "   2780376738,\n",
              "   2377407998,\n",
              "   612309705,\n",
              "   4022217260,\n",
              "   145755354,\n",
              "   1197274402,\n",
              "   2864745435,\n",
              "   785158184,\n",
              "   2929020350,\n",
              "   2624244444,\n",
              "   2305172445,\n",
              "   385008522,\n",
              "   1586994231,\n",
              "   3364142944,\n",
              "   2792622598,\n",
              "   282464476,\n",
              "   3934117936,\n",
              "   663856099,\n",
              "   1481473113,\n",
              "   2473556877,\n",
              "   1891142661,\n",
              "   1806471136,\n",
              "   3303404999,\n",
              "   643428304,\n",
              "   2743783205,\n",
              "   1364094123,\n",
              "   1967706160,\n",
              "   1731686210,\n",
              "   1762595116,\n",
              "   4259640713,\n",
              "   2559822860,\n",
              "   4180542658,\n",
              "   2167777286,\n",
              "   1967162872,\n",
              "   2895285416,\n",
              "   663430439,\n",
              "   4250518387,\n",
              "   952028405,\n",
              "   1000821632,\n",
              "   2828637441,\n",
              "   1092507163,\n",
              "   3814413103,\n",
              "   3287316856,\n",
              "   1668853702,\n",
              "   1716824537,\n",
              "   3907783919,\n",
              "   1698246227,\n",
              "   2974720843,\n",
              "   2675588763,\n",
              "   2910429335,\n",
              "   4125537033,\n",
              "   2888110046,\n",
              "   4007556931,\n",
              "   3433379937,\n",
              "   789473525,\n",
              "   3382271682,\n",
              "   1305684503,\n",
              "   3665380521,\n",
              "   1897087331,\n",
              "   4154109381,\n",
              "   1629231367,\n",
              "   3551134043,\n",
              "   2506406055,\n",
              "   3675659950,\n",
              "   2671214925,\n",
              "   1503078796,\n",
              "   1480460103,\n",
              "   1064347336,\n",
              "   1291999839,\n",
              "   3518050595,\n",
              "   3737618022,\n",
              "   3157675903,\n",
              "   4048671755,\n",
              "   940172404,\n",
              "   942766100,\n",
              "   99729475,\n",
              "   4216434466,\n",
              "   1056744432,\n",
              "   2397173520,\n",
              "   1106400688,\n",
              "   798407436,\n",
              "   35728481,\n",
              "   93721789,\n",
              "   2247488111,\n",
              "   3690461826,\n",
              "   667387937,\n",
              "   624),\n",
              "  None),\n",
              " '_restored_from_state': False,\n",
              " 'batch_size': 128,\n",
              " 'batch_size_fn': None,\n",
              " 'batches': <generator object batch at 0x7f065384f468>,\n",
              " 'dataset': <torchtext.data.dataset.Dataset at 0x7f065276f5c0>,\n",
              " 'device': device(type='cuda'),\n",
              " 'iterations': 16,\n",
              " 'random_shuffler': <torchtext.data.utils.RandomShuffler at 0x7f0653843f60>,\n",
              " 'repeat': False,\n",
              " 'shuffle': False,\n",
              " 'sort': False,\n",
              " 'sort_key': None,\n",
              " 'sort_within_batch': False,\n",
              " 'train': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 358
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsNh5V1GUje4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gx4jd1NUkV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crJ2dYugUldO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDMys7JiUmTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d616a721-0cff-4394-c7f6-e74614feee93"
      },
      "source": [
        "N_EPOCHS = 50\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut5-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.597 | Train Acc: 23.73%\n",
            "\t Val. Loss: 1.604 |  Val. Acc: 22.91%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.596 | Train Acc: 23.78%\n",
            "\t Val. Loss: 1.605 |  Val. Acc: 22.78%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.598 | Train Acc: 22.22%\n",
            "\t Val. Loss: 1.605 |  Val. Acc: 22.72%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.601 | Train Acc: 22.51%\n",
            "\t Val. Loss: 1.611 |  Val. Acc: 22.78%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.590 | Train Acc: 23.00%\n",
            "\t Val. Loss: 1.604 |  Val. Acc: 22.78%\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.598 | Train Acc: 22.66%\n",
            "\t Val. Loss: 1.599 |  Val. Acc: 22.83%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.591 | Train Acc: 24.02%\n",
            "\t Val. Loss: 1.607 |  Val. Acc: 22.78%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.594 | Train Acc: 24.22%\n",
            "\t Val. Loss: 1.599 |  Val. Acc: 22.66%\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.594 | Train Acc: 23.83%\n",
            "\t Val. Loss: 1.612 |  Val. Acc: 22.78%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.595 | Train Acc: 23.73%\n",
            "\t Val. Loss: 1.601 |  Val. Acc: 22.66%\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.598 | Train Acc: 23.44%\n",
            "\t Val. Loss: 1.602 |  Val. Acc: 23.23%\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.591 | Train Acc: 24.90%\n",
            "\t Val. Loss: 1.605 |  Val. Acc: 22.78%\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.594 | Train Acc: 22.85%\n",
            "\t Val. Loss: 1.606 |  Val. Acc: 22.78%\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.598 | Train Acc: 23.78%\n",
            "\t Val. Loss: 1.609 |  Val. Acc: 22.78%\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.592 | Train Acc: 24.56%\n",
            "\t Val. Loss: 1.599 |  Val. Acc: 23.17%\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.593 | Train Acc: 24.46%\n",
            "\t Val. Loss: 1.615 |  Val. Acc: 22.78%\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.593 | Train Acc: 24.41%\n",
            "\t Val. Loss: 1.604 |  Val. Acc: 22.78%\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.598 | Train Acc: 22.56%\n",
            "\t Val. Loss: 1.600 |  Val. Acc: 22.83%\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.596 | Train Acc: 22.80%\n",
            "\t Val. Loss: 1.606 |  Val. Acc: 22.72%\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.596 | Train Acc: 24.27%\n",
            "\t Val. Loss: 1.601 |  Val. Acc: 22.66%\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.597 | Train Acc: 23.63%\n",
            "\t Val. Loss: 1.609 |  Val. Acc: 22.78%\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.598 | Train Acc: 23.63%\n",
            "\t Val. Loss: 1.606 |  Val. Acc: 22.72%\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.592 | Train Acc: 23.44%\n",
            "\t Val. Loss: 1.601 |  Val. Acc: 23.36%\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.592 | Train Acc: 24.02%\n",
            "\t Val. Loss: 1.602 |  Val. Acc: 22.66%\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.590 | Train Acc: 24.76%\n",
            "\t Val. Loss: 1.606 |  Val. Acc: 22.72%\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.595 | Train Acc: 23.93%\n",
            "\t Val. Loss: 1.611 |  Val. Acc: 22.72%\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.602 | Train Acc: 23.19%\n",
            "\t Val. Loss: 1.599 |  Val. Acc: 22.78%\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.592 | Train Acc: 22.80%\n",
            "\t Val. Loss: 1.602 |  Val. Acc: 22.66%\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.594 | Train Acc: 22.75%\n",
            "\t Val. Loss: 1.600 |  Val. Acc: 22.66%\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.596 | Train Acc: 22.41%\n",
            "\t Val. Loss: 1.603 |  Val. Acc: 22.78%\n",
            "Epoch: 31 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.594 | Train Acc: 24.51%\n",
            "\t Val. Loss: 1.599 |  Val. Acc: 22.66%\n",
            "Epoch: 32 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.595 | Train Acc: 23.68%\n",
            "\t Val. Loss: 1.603 |  Val. Acc: 22.78%\n",
            "Epoch: 33 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.587 | Train Acc: 25.10%\n",
            "\t Val. Loss: 1.602 |  Val. Acc: 22.66%\n",
            "Epoch: 34 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.590 | Train Acc: 24.27%\n",
            "\t Val. Loss: 1.604 |  Val. Acc: 22.66%\n",
            "Epoch: 35 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.591 | Train Acc: 24.12%\n",
            "\t Val. Loss: 1.601 |  Val. Acc: 22.66%\n",
            "Epoch: 36 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.594 | Train Acc: 24.32%\n",
            "\t Val. Loss: 1.600 |  Val. Acc: 22.66%\n",
            "Epoch: 37 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.593 | Train Acc: 23.97%\n",
            "\t Val. Loss: 1.601 |  Val. Acc: 22.66%\n",
            "Epoch: 38 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.592 | Train Acc: 24.22%\n",
            "\t Val. Loss: 1.599 |  Val. Acc: 22.78%\n",
            "Epoch: 39 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.601 | Train Acc: 22.17%\n",
            "\t Val. Loss: 1.605 |  Val. Acc: 22.78%\n",
            "Epoch: 40 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.594 | Train Acc: 25.34%\n",
            "\t Val. Loss: 1.606 |  Val. Acc: 22.78%\n",
            "Epoch: 41 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.594 | Train Acc: 24.12%\n",
            "\t Val. Loss: 1.601 |  Val. Acc: 22.66%\n",
            "Epoch: 42 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.594 | Train Acc: 23.97%\n",
            "\t Val. Loss: 1.603 |  Val. Acc: 22.78%\n",
            "Epoch: 43 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.599 | Train Acc: 23.00%\n",
            "\t Val. Loss: 1.605 |  Val. Acc: 22.78%\n",
            "Epoch: 44 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.595 | Train Acc: 23.68%\n",
            "\t Val. Loss: 1.602 |  Val. Acc: 22.78%\n",
            "Epoch: 45 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.592 | Train Acc: 24.32%\n",
            "\t Val. Loss: 1.602 |  Val. Acc: 22.66%\n",
            "Epoch: 46 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.596 | Train Acc: 23.88%\n",
            "\t Val. Loss: 1.603 |  Val. Acc: 22.66%\n",
            "Epoch: 47 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.602 | Train Acc: 22.51%\n",
            "\t Val. Loss: 1.602 |  Val. Acc: 22.66%\n",
            "Epoch: 48 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.595 | Train Acc: 23.00%\n",
            "\t Val. Loss: 1.600 |  Val. Acc: 22.78%\n",
            "Epoch: 49 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.594 | Train Acc: 22.22%\n",
            "\t Val. Loss: 1.611 |  Val. Acc: 22.78%\n",
            "Epoch: 50 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.592 | Train Acc: 24.27%\n",
            "\t Val. Loss: 1.598 |  Val. Acc: 22.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqVqHERmUnKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}